# Exercise 2

*Describe the work you have done this week and summarize your learning.*

```{r eval = T, echo = F, message = F, warning = F}
# Load dplyr library for nice'n'easy functions for data wrangling.
library(dplyr)
library(GGally)
library(ggplot2)

# Import the data
d <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep = "\t", header = TRUE)

# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")

# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(d, one_of(deep_questions))
d$deep <- rowMeans(deep_columns)

# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(d, one_of(surface_questions))
d$surf <- rowMeans(surface_columns)

# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(d, one_of(strategic_questions))
d$stra <- rowMeans(strategic_columns)

# let's also take mean from Attitude vars:
d$attitude <- d$Attitude/10

# Create an analysis dataset: 1. select right variables, 2. filter rows that has
a <- d %>% 
  select(gender, Age, attitude, deep, stra, surf, Points) %>% 
  filter(Points != 0)

# Fix the column names to be all lowercase
names(a) <- tolower(names(a))

```

In this exercise we are taking the first look on *learning2014*, a survey data from Introduction to Social Statistics course, fall 2014. In our dataset there's 166 observations and 7 variables:

- *gender*
- *age*
- *attitude* (global attitude toward statistics)
- *deep* (pursuit for deep understanding of the topics)
- *stra* (having plans or strategy in learning process)
- *surf* (focusing on surface level things such as passing the course and thinking about it as a performance)
- *points* (exam points).


## Overview of the data
In R, the dataset is named as *a* and its structure is like this:

```{r echo = F, eval = T}
str(a)
```

Below there are scatterplots and some basic stats about the variables. The pinks are female, cyans are male. If we look at just the distributions of each variable by gender, we can see that male students win the gender competition in the attitude towards statistics (*attitude*) but lose in strategic learning (*stra*). We can also see that exam points correlate the most positively with *attitude* and most negatively with *surf*. That is perhaps not a surprise! 

```{r echo = F, eval = T}
ggpairs(a, mapping = aes(col = gender, alpha = .3), lower = list(combo = wrap("facethist", bins = 20))) +
  theme_bw() +
  theme(panel.grid = element_blank())
```

## Linear regression model

Let's build a linear regression model that predicts exam points (*points*) using some of the other variables as predictors. For now, we'll select three variables that have the strongest positive or negative correlation with *points*: *attitude*, *surf* and *stra*.

```{r eval = T, echo = F}
fit <- lm(data = a, formula = points ~ attitude + surf + stra)
summary(fit)
```

In the *Estimate* column we can see estimated parameter values for each predictor. If the value is positive, then high values of that variable indicate high points in the exam. If negative, then vice versa. A parameter value close to zero suggests no connection between the predictor and exam points. 

To test the null hypothesis that the real parameter value is zero, one can use t-test. In the summary above, the test statistic and its 2-sided p-value have been included in the table. Low p-value (< .05) of a test statistic indicates that the parameter value is non-zero and the variable should stay in the model.

It seems that the attitude is all that matters! So let's just remove the other predictors from the model.

```{r eval = T, echo = F}
fit <- lm(data = a, formula = points ~ attitude)
summary(fit)
```

In our final model, we have only one predictor: *attitude*, whose parameter value is `r round(fit$coefficients["attitude"], 2)`. It means that 1 unit increase in attitude results in `r round(fit$coefficients["attitude"], 2)` points increase in exam points.

The multiple R-squared of the model is around 20 %. It means that *attitude* explains 20 % of the variation in exam points. Better to keep that in mind!

## Model diagnostics

Let's draw some diagnostics plots. When plotting residuals agains fitted values, we can see:

- The dependence between *attitude* and *points* seems linear. There's no indication of it being something else.
- No noticable difference in the residual variance between high and low scoring students in the exam.
- The most extreme outliers are not that extreme.

```{r eval = T, echo = F}
plot(fit, which = 1)
```

From theoretical quantiles we can see that the residuals are not perfectly normally distributed. But it could be worse. In case of normally distributed residuals, the points would follow the straight dashed line.

```{r eval = T, echo = F}
plot(fit, which = 2)
```

By plotting standardized residuals against Leverage, we can find influential outliers -- those that matter. This time, the dashed red line marking the Cook's distance doesn't even show up in the plot, so there are no such outliers we should be too worried about. Problematic outliers would appear in the plot in upper or lower right corner beyond Cook's distance, perhaps we'll get an example of that later on this course!

```{r eval = T, echo = F}
plot(fit, which = 5)
```


